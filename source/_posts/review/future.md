---
title: Future
date: 2020-03-30 00:00:00
author: vanliuzh
top: true
cover: false
toc: true
mathjax: false
categories: Java
tags: [Java, Note]
reprintPolicy: cc_by
---

# Conncurrennt 并发

并发编程JUC知识点总结

## 知识点概况

1. 竞态条件和临界资源

2. JMM -- Java Memony Model 是一种抽象，一组规则，围绕着3个特性展开，如何做到这三点就是我们需要理解的

    1. 原子性
    2. 有序性
    3. 可见性

3. 监视器 Monitor

4. JTI 即时编译，通过热点探测（对程序计数统计）

5. 并发编程模型

    线程如何`通信`和`同步`

6. 上下文: 某一时间点，CPU寄存器和计数器的内容(还有栈信息等)，线程只需要保存这些内容做切换

7. CLH锁即Craig, Landin, and Hagersten (CLH) locks。CLH锁是一个自旋锁。能确保无饥饿性。提供先来先服务的公平性

线程的上下文信息是保存在内存中的，切换回来的时候去内存中找到然后恢复到寄存器中

## 创建线程的方式

1. 实现Runable接口
2. 继承Thread类
3. 实现Callable接口

1，2都是类似的，3是用线程池

7. 被阻塞的线程不会消耗CPU，但是线程状态的转换需要相对比较长的时间

8. park unpark 挂起，恢复

## start 和 run 方法的区别

start方法会创建线程，进入就绪状态，分配到时间的时候片执行run方法
直接用run方法不会有多线程，就和普通的方法一样

## 线程状态

1. wait(),join(),LockSupport.lock()方法线程会进入到WAITING

2. wait(long timeout)，sleep(long),join(long),LockSupport.parkNanos(),LockSupport.parkUtil()增加了超时等待的功能，也就是调用这些方法后线程会进入TIMED_WAITING

3. 当超时等待时间到达后，线程会切换到Runable的状态，另外当WAITING和TIMED_WAITING状态时可以通过Object.notify(),Object.notifyAll()方法使线程转换到Runable状态

4. 当线程出现资源竞争时，即等待获取锁的时候，线程会进入到BLOCKED阻塞状态

5. 当线程获取锁时，线程进入到Runable状态

6. 线程运行结束后，线程进入到TERMINATED状态

7. 当线程进入到synchronized方法或者synchronized代码块时，线程切换到的是BLOCKED状态，而使用java.util.concurrent.locks下lock进行加锁的时候线程切换的是WAITING或者TIMED_WAITING状态，因为lock会调用LockSupport的方法。

## 线程基本操作

1. interrupted 中断

主要关注标志位的状态，标志位用来做判断，
interrupted interrupt isInterrupted

2. join

3. sleep

sleep线程不会失去锁

sleep()方法是Thread的静态方法，而wait是Object实例方法

wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。
而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁；

sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行

4. yield

调用后当前线程让出时间片，拥有同级别优先级的线程可以去竞争该时间片，让出时间片后，加入到下一次的cpu资源竞争中

## 获取线程的状态

```java
System.out.println("线程唯一标识符：" + thread.getId());
System.out.println("线程名称：" + thread.getName());
System.out.println("线程状态：" + thread.getState());
System.out.println("线程优先级：" + thread.getPriority());
```

## notify notifyAll 

## Daemon 守护线程

一个进程包含主线程，2个子线程，1个守护线程

主线程任务完成了，子线程任务也完成了，这个时候守护线程会自己结束，不管任务有没有完成

## 什么是线程安全？

当多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那这个对象是线程安全的。

## 线程通信，消费者和生产者编程实践

## Java中共享变量是哪些？

方法中的局部变量不是共享的，实例域，静态域和数组元素都是在堆内存中的，是共享的

## Java内存模型

## 重排序

分类

1. 编译器优化的重排序

编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序

2. 指令级并行的重排序

现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序

3. 内存系统的重排序

由于处理器使用缓存，读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的，详细说明下这种情况

举例: 

- 什么是缓冲区

发生这种情况是由于处理器使用了缓冲区，比如对变量的写入先写到缓冲区，然后再刷新到主存(现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟)

- 场景

理解这个概念后，有一段代码执行顺序是这样的，A，B线程，先写a=1，b=2到主存，然后读取主存共享变量 a=b=0

- 执行情况

内存的操作情况是 写，然后读(`写->读`) 然而有缓冲区，可能是写到缓冲区后，读主存，然后缓冲区刷新到主存(`读->写`)

- 结论

由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。可以用

常见的处理器都允许Store-Load重排序；
常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO和x86拥有相对较强的处理器内存模型，它们`仅允许对写-读操作做重排序`（因为它们都使用了写缓冲区）

- 通过内存屏障解决重排序问题

Java编译器通过插入内存屏障来解决重排序，内存屏障是指令，依托于处理器的实现，使用内存屏障有一定的性能损坏，因为原来通过缓冲区加快了处理器指令流水的运行，使用内存屏障就是要先把缓冲区数据刷新到主存后，才执行后面的指令

- 内存屏障指令举例 

`LoadLoad Barriers`    

Load1; LoadLoad; Load2   确保Load1数据的装载，之前于Load2及所有后续装载指令的装载

`StoreLoad Barriers`   

Store1; StoreStore; Store2  确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储

`LoadStore Barriers`   

Load1; LoadStore; Store2   确保Load1数据装载，之前于Store2及所有后续的存储指令刷新到内存

`StoreLoad Barriers`   

Store1; StoreLoad; Load2   确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令

- 内存屏障总结

StoreLoad Barriers 是现代处理器都会支持的(其它的不一定)。总的来说内存屏障指令之前的指令，会先执行，有写操作的都要刷新主存后，后面的指令才执行，这样后面的指令就能读到前一个指令写入的数据(从主存读)，实现了数据的可见性

`重排序`

对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序(不是所有的编译器重排序都要禁止)。对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障(memory barriers，intel称之为memory fence)指令，通过内存屏障指令来禁止特定类型的处理器重排序(不是所有的处理器重排序都要禁止)

JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证

总结: 重排序是对Java源代码编译后的字节码做排序，现代处理都能并行处理，也就是一次执行多条指令，而旧体系的处理器或者单片机是按照时钟周期一条一条指令执行的。编译器编译源代码，处理器去执行语句都可能发生重排序


## 什么时候不能重排序？

发生数据依赖的时候，不能重排序

如果两个操作访问同一个变量，且这两个操作有一个为写操作，此时这两个操作就存在数据依赖性，体现在`有写操作`上

读后写，写后读，写后写 都是数据依赖  读后读  没关系，都是读取

## as-if-serial

遵守as-if-serial语义的编译器，runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的

## happens-before

通过happens-before来描述内存可见性，或者说是`用来描述可见性的一种规则`

## 缓存一致性

指的是使用了缓存和数据库的情况下，如何保证数据一致性，我们会把高频读的数据放到缓存，但是修改数据库的时候需要把缓存删除，再建立新的

1. 先删缓存再改数据库

可能会有这样的问题

并发，1读，1写

- `写1`先删了`缓存`
- 这个时候`读1`发现没`缓存`，就读数据库准备写到`缓存`
- 然后`写1`要把数据写到`数据库`
- 接着`读1`把自己读到的数据写到`缓存`

这样缓存是`读1`放入的旧数据，数据库是`写1`放入的新数据，出现不一致

2. 先读数据库，再删除缓存

- 一开始没有缓存，读写并发
- 读操作先进来，发现没有缓存，去数据库中读数据，这个时候因为某种原因卡了，没有及时把数据放入缓存
- 写的操作进来了，修改了数据库，删除了缓存
- 读操作恢复，把老数据写进了缓存

这种情况下，读操作本来是要马上写缓存的，但是被写操作抢先了，写了新的数据进入，写操作的删除缓存没意义了，被后面读操作覆盖了

其实这种情况很极端了，但是会存在，因为并发，操作不是原子的

但是写一般是比较慢的，除非你读慢于写，才会发生

3. 延迟双删

延迟双删就是写中，先删除缓存，后修改数据库，最后延迟一定时间，再次删除缓存

这样写保证缓存不是旧缓存，是2情况的一种延时策略，缓存由读操作去建立，写操作保证不要写入旧缓存，否则读一直是旧缓存

4. 内存队列，消息队列

在3中，如果第二次删除失败了，那么就会有2的情况发生，上面3点都存在以下问题

- 修改数据库、删除缓存这两个操作耦合在了一起，没有很好的做到单一职责；
- 如果写操作比较频繁，可能会对Redis造成一定的压力；
- 如果删除缓存失败，该怎么办？

写操作只是修改数据库，然后把数据的Id放在内存队列里面，后台会有一个线程消费内存队列里面的数据，删除缓存，如果缓存删除失败，可以重试多次

生产考虑用消息队列，这样各个部门的数据都可以入队列，然后在容器或者整个服务里面启动一个服务，专门去消费队列，删除缓存

很好的解决了缓存不一致的问题，但是存在一定的延迟

说了这么多，有没有发现有点CAP的影子，保证了可用性，缺牺牲了一致性，但是保证了最终一致性

## 事件多播器

## 让你去实现一个注册中心，你会怎么做？

## 让你实现一个消息中间件，比如kafka，你会怎么做？

## dubbo调用的请求参数和返回参数无法使用泛型是因为什么

## dubbo 知识点

service 标签 暴露的服务
reference 标签 服务引用，标识从注册用心引用其它服务给自己用

推荐使用 Hessian 序列化

## zk

容器连接客户端

docker exec -it zookeeper /opt/zookeeper-3.4.13/bin/zkCli.sh -server 127.0.0.1:2181
docker exec -it zookeeper /opt/zookeeper-3.4.13/bin/zkServer.sh status

## zk选举

通常节点数要是偶数，因为集群过半投票后，才能选出新的leader，选不出就不提供服务

脑裂: 实际是不会有脑裂的，因为不满足过半条件，集群不再提供服务（过半机制防止脑裂）

假设有5台，过半就是5/2余数2，要大于2才行，也就是3，不能是等于2。也就是说集群必须存活着3台才能选举出新的leader，所以在5台组成的集群中，只能挂2台

在考虑选举的时候，是所有的，包括挂了的作为总数来计算，上面的例子就是5。假设总共有6台，分在2个机房，一个机房A 3台，另一个B也是3台，由于6/2等3，需要4台才能选出leader，所以AB机房都选不出，服务不可用。如果是AB分配是4，2那么A机房能选出leader，整个集群只有一个leader，这也是过半原则要大于的原因，如果是大于等于，在AB分配3，3的情况下，AB都满足等于3，都会选出leader，那就脑裂了

还有一个知识点就是部署最好是奇数，虽然奇数，偶数的集群都能选出leader，都不会脑裂，但是奇数能节约资源

5的情况下，运行挂2台(5/2 余 2，需要3台才能进行选举，所以容错是2台)，6的情况下，也是运行挂2台，那么我用5台就好了，节约资源

## Spring

源码流程

AnnotationConfigApplicationContext 通过注解配置创建context

在构造函数中，做了下面的事情

// 1.初始化bean定义读取器和扫描器
// 2.调用父类GenericApplicationContext无参构造函数，初始化一个BeanFactory：DefaultListableBeanFactory
// 3.注册Spring自带的bean，共5个 包括: 
//  ConfigurationClassPostProcessor
//  AutowiredAnnotationBeanPostProcessor  CommonAnnotationBeanPostProcessor
// 	EventListenerMethodProcessor  DefaultEventListenerFactory

1. 数据结构，算法

看视频部分，一次过，总结一些小东西即可，B+树，红黑树要会，还有hash表，堆

以前用过的一致性hash，hash环

2. 基础

基础语法
反射，代理，class对象
新语法，lambda，流处理

2. 语言扩展相关

jvm,juc（并发容器，并发编程，AQS等）

3. 框架，构建工具

maven，Spring，Spring boot

4. 数据库

MySQL 原理，存储引擎，innodb，索引，锁，事务，事务隔离

读写分离，主从同步

框架结合: 读写分离配置，多数据源配置，事务声名怎么用，分布式事务怎么用

优化，扩展

innodb_flush_log_at_trx_commit MySql日志何时写入硬盘的参数
load data infile 从文件把数据写入表中
存储过程upset，适合去重，利用upset，有就更新，无就创建
ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

5. Redis

集群，数据结构，红锁，分布式事务

6. 中间件

kafka,rocketmq

7. 微服务,分布式，soa

k8s, spring cloud ，dubbo

8. 能力开放平台

9. 分布式锁


链接:https://pan.baidu.com/s/1pCViJ2lYrrl-k3-ic8ADZg  密码:mimx

